---
title: "FIFA20 Regression Problems"
author: "Naga Santhosh Kartheek Karnati"
date: "3/28/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(stringr)
library(data.table)
library(rio)
library(modelr)
library(purrr)



f20 <- fread('D:/NEU/Spring 2020/SML/Project/Datasets/players_20.csv')

f20 <- as_tibble(f20)

f20 <- f20 %>% select(-player_url, -long_name, -dob, -player_positions, -body_type, -real_face,
                      -real_face, -player_tags, -loaned_from, -joined, -contract_valid_until, 
                      -nation_position, -nation_jersey_number, -player_traits)

f20 <- f20 %>% select(-(66:91))

#View(f20)


f20_sans_gks <- f20 %>% select(-gk_diving, -gk_handling, -gk_kicking, -gk_reflexes,
                               -gk_speed, -gk_positioning, -goalkeeping_diving,
                               -goalkeeping_handling, -goalkeeping_kicking, 
                               -goalkeeping_positioning, -goalkeeping_reflexes)

f20_gks <- f20%>% select(age, height_cm, weight_kg, overall, potential, value_eur, wage_eur,
                         international_reputation, weak_foot, release_clause_eur, gk_diving, gk_handling, gk_kicking, gk_reflexes, gk_speed,
                         gk_positioning) %>% 
  filter(!is.na(gk_diving))

dim(f20_gks)

```

## LINEAR MODEL: FULL SUBSET SELECTION
```{r}
library(purrr)
#Players excluding GKs:
#Full subset selection:
full_subset_model <- lm(wage_eur~. , data = subset(f20_sans_gks, select = c(- short_name, -sofifa_id, -nationality, -club, -preferred_foot, 
     -team_position, -team_jersey_number, -work_rate)))


#Summary of the model for feature selection:
summary(full_subset_model)
#Features that influence wage the mmost:
#age, height, weight, value, international_reputation, release clause, skill fk accuracy,
#skill long passing and mentality composure.
```


## FORWARD FEATURE SELECTION:
```{r}
#Forward selection:
library(leaps)
ffs_fit <- regsubsets(wage_eur~., data= subset(f20_sans_gks, select = c(- short_name, -sofifa_id, -nationality, -club, -preferred_foot, 
     -team_position, -team_jersey_number, -work_rate)), method = "forward")

ffs_fit_summary <- summary(ffs_fit)
coef(ffs_fit, 8)
names(ffs_fit)
#The features influencing wage the most: age, value, international reputation,
#release clause, attacking crossing, fk accuracy, mentality composure and sliding tackle.

```

## RRS, Adjr2, Cp and BIC measures:
```{r}

par(mfrow=c(2,2))
plot(ffs_fit_summary$rss,xlab="Number of Variables",ylab="RSS",type="l")

plot(ffs_fit_summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
which.max(ffs_fit_summary$adjr2)
points(8,ffs_fit_summary$adjr2[8], col="red",cex=2,pch=20)

plot(ffs_fit_summary$cp,xlab="Number of Variables",ylab="Cp",type='l')
which.min(ffs_fit_summary$cp)
points(8,ffs_fit_summary$cp[8],col="red",cex=2,pch=20)

which.min(ffs_fit_summary$bic)
plot(ffs_fit_summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
points(6,ffs_fit_summary$bic[8],col="red",cex=2,pch=20)

```


```{r}
plot(ffs_fit,scale="r2")
plot(ffs_fit,scale="adjr2")
plot(ffs_fit,scale="Cp")
plot(ffs_fit,scale="bic")
```


## LINEAR MODEL FOR GKs:
```{r}

#Full subset selection for goalkeepers:
full_subset_model_gk <- lm(wage_eur~. , data=f20_gks)
summary(full_subset_model_gk)
#Features that influence goalkeeper's wage:
#age, height, value, international reputation and release clause.

```


## Stepwise Forward selection for GKs:
```{r}
ffs_fit_gks <- regsubsets(wage_eur ~ ., data = f20_gks, method = "forward")
ffs_fit_gks_summary <- summary(ffs_fit_gks)
coef(ffs_fit_gks, 8)
#features selected in stepwise forward selection: age, height, weight, overall, value,
#international reputation, release clause, gk positioning.

```

## RSS, Adjr2, Cp and BIC measures:
```{r}
par(mfrow=c(2,2))
plot(ffs_fit_gks_summary$rss,xlab="Number of Variables",ylab="RSS",type="l")

plot(ffs_fit_gks_summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
which.max(ffs_fit_gks_summary$adjr2)
points(5,ffs_fit_gks_summary$adjr2[8], col="red",cex=2,pch=20)

plot(ffs_fit_gks_summary$cp,xlab="Number of Variables",ylab="Cp",type='l')
which.min(ffs_fit_gks_summary$cp)
points(5,ffs_fit_gks_summary$cp[8],col="red",cex=2,pch=20)

which.min(ffs_fit_gks_summary$bic)
plot(ffs_fit_gks_summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
points(4,ffs_fit_gks_summary$bic[8],col="red",cex=2,pch=20)


```


## Player overall: FULL SUBSET SELECTION
```{r}
#Player overall
ovr_model <- lm(overall~. , data = subset(f20_sans_gks, select = c(- short_name, -sofifa_id, -nationality, -club, -preferred_foot, 
     -team_position, -team_jersey_number, -work_rate)))


#Summary of the model for feature selection:
summary(ovr_model)



```

```{r}
#The significant variables to predict overall are: age, weight_kg, potential, value_eur,
#international_reputation, weak_foot, skill_moves, release_clause_eur, attacking _heading,
#attacking short passing, skill curve, skill ball control, movement reactions, movement
#balance, mentality positioning, mentality vision, mentality composure, defending sliding
#tackle.
#dataset containing only these variables:
overall_full_subset <- f20_sans_gks %>% select(overall, age, weight_kg, potential, value_eur, international_reputation, weak_foot, skill_moves, release_clause_eur, 
      attacking_heading_accuracy, attacking_short_passing, skill_curve, skill_ball_control,
      movement_reactions, movement_balance, mentality_positioning, mentality_vision,
      mentality_composure, defending_sliding_tackle)
#perform linear regression on this dataset to predict player value.
#str(overall_full_subset)
```


## Player overall: STEPWISE FORWARD SELECTION
```{r}
ovr_ffs_model <- regsubsets(overall ~ ., data= subset(f20_sans_gks, select = c(- short_name, -sofifa_id, -nationality, -club, -preferred_foot, 
     -team_position, -team_jersey_number, -work_rate)), method = "forward")
ovr_ffs_model_summary <- summary(ovr_ffs_model)
ovr_ffs_model
coef(ovr_ffs_model, 8)


```


```{r}
#significant variables to predict overall using stepwise forward selection are age,
#potential, value_eur, skill ball control, movement reactions, power stamina, power
#stamina, mentality composure.
overall_step_forward <- f20_sans_gks %>% select(overall, age, potential, value_eur,
      skill_ball_control, movement_reactions, power_stamina, power_strength,
      mentality_composure)
#use this dataset to predict overall.
```


## RSS, Adjr2, Cp and BIC measures:
```{r}
par(mfrow=c(2,2))
plot(ovr_ffs_model_summary$rss,xlab="Number of Variables",ylab="RSS",type="l")

plot(ovr_ffs_model_summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
which.max(ovr_ffs_model_summary$adjr2)
points(8,ovr_ffs_model_summary$adjr2[8], col="red",cex=2,pch=20)

plot(ovr_ffs_model_summary$cp,xlab="Number of Variables",ylab="Cp",type='l')
which.min(ovr_ffs_model_summary$cp)
points(8,ovr_ffs_model_summary$cp[8],col="red",cex=2,pch=20)

which.min(ovr_ffs_model_summary$bic)
plot(ovr_ffs_model_summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
points(8,ovr_ffs_model_summary$bic[8],col="red",cex=2,pch=20)


```

## Value vs overall analysis:
```{r}
f20_sans_gks_no0value <- f20_sans_gks%>%
  filter(value_eur != 0)

val_ovr_fit <- lm(log(value_eur) ~ overall, data= subset(f20_sans_gks_no0value, select = c(- short_name, -sofifa_id, -nationality, -club, -preferred_foot, 
     -team_position, -team_jersey_number, -work_rate)))

summary(val_ovr_fit)

subset(f20_sans_gks_no0value, select = c(- short_name, -sofifa_id, -nationality, -club, -preferred_foot, 
     -team_position, -team_jersey_number, -work_rate))%>% 
  add_predictions(val_ovr_fit)%>%
  ggplot(aes(overall))+
  geom_point(aes(y=log(value_eur))) +
geom_line(aes(y=pred))


```


#Predicting player overall using linear regression: full subset selection dataset
```{r}
library(caret)
#using the full subset selection dataset and results to predict overall:
#View(overall_full_subset)
dim(overall_full_subset)
#split data into testing and training sets:
set.seed(1)
training.samples <- overall_full_subset$overall %>% createDataPartition(p = 0.8, list = FALSE)
train.data  <- overall_full_subset[training.samples, ]
test.data <- overall_full_subset[-training.samples, ]
dim(train.data)
dim(test.data)

```

```{r}
#fit a linear model on the train set:
ovrfsm <- lm(overall~. ,data = na.omit(train.data))
#summary of the linear model:
summary(ovrfsm)
#AIC and BIC of linear model:
AIC(ovrfsm)
BIC(ovrfsm)
#AIC=58346.9 BIC=58497.24
#predicted overall:
ovrpred <- predict(ovrfsm, test.data)

comparison_df <- data.frame(cbind(actual= test.data$overall, predicted = ovrpred))
#View(comparison_df)

#correlation accuracy:
cor(comparison_df, use = "complete.obs")    #95.6%

dim(comparison_df)
dim(na.omit(comparison_df))

comparison_df <- na.omit(comparison_df)

#RMSE and MAE:
# Function that returns Root Mean Squared Error
rmse <- function(error)
{
    sqrt(mean(error^2))
}
 
# Function that returns Mean Absolute Error
mae <- function(error)
{
    mean(abs(error))
}

#error in the model:
error <- comparison_df$predicted - comparison_df$actual

########VALIDATION SET APPROACH:
#RMSE:
rmse(error)   #2.032
#MAE:
mae(error)    #1.590


#######LOOCV:
# Define training control
train.control <- trainControl(method = "LOOCV")
# Train the model
ovrfs_loocv_model <- train(overall ~., data = na.omit(train.data), method = "lm",
               trControl = train.control)
# Summarize the results
print(ovrfs_loocv_model)
summary(ovrfs_loocv_model)

#predicted overall:
ovrpred_loocv <- predict(ovrfs_loocv_model, test.data)

comparison_df <- data.frame(cbind(actual= test.data$overall, predicted = ovrpred_loocv))
#View(comparison_df)

#correlation accuracy:
cor(comparison_df, use = "complete.obs")    #46.7%

#error using loocv method:
error <- comparison_df$predicted - comparison_df$actual
#RMSE:
rmse(error)    #7.33
#MSE:
mae(error)     #3.56



########k Fold Cross Validation:
set.seed(2310) 
train.control <- trainControl(method = "cv", number = 10)
# Train the model
ovrfs_kfcv_model <- train(overall ~., data = na.omit(train.data), method = "lm",
               trControl = train.control)
# Summarize the results
print(ovrfs_kfcv_model)
summary(ovrfs_kfcv_model)

#predicted overall:
ovrpred_kfcv <- predict(ovrfs_kfcv_model, test.data)

comparison_df <- data.frame(cbind(actual= test.data$overall, predicted = ovrpred_kfcv))
#View(comparison_df)

#correlation accuracy:
cor(comparison_df, use = "complete.obs")    #46.7%

#error using loocv method:
error <- comparison_df$predicted - comparison_df$actual
#RMSE:
rmse(error)    #7.33
#MSE:
mae(error)     #3.56


```

#Predicting player overall using stepwise forward selection model dataset:
```{r}
#View(overall_step_forward)
dim(overall_step_forward)
#split data into testing and training sets:
set.seed(987)
training.samples <- overall_step_forward$overall %>% createDataPartition(p = 0.8, list = FALSE)
train.data  <- overall_step_forward[training.samples, ]
test.data <- overall_step_forward[-training.samples, ]
dim(train.data)
dim(test.data)

```

```{r}
#predicting overall using validation set approach, loocv and kfcv:
#####Validaiton set apparoach:
#fit a linear model on the train set:
ovrstfsm <- lm(overall~. ,data = na.omit(train.data))
#summary of the linear model:
summary(ovrstfsm)
#AIC and BIC of linear model:
AIC(ovrstfsm)
BIC(ovrstfsm)
#AIC = 63303 and BIC = 63379.5

#predicted overall:
ovrpred <- predict(ovrstfsm, test.data)

comparison_df <- data.frame(cbind(actual= test.data$overall, predicted = ovrpred))
#View(comparison_df)

#correlation accuracy:
cor(comparison_df, use = "complete.obs")    #95.5%

comparison_df <- na.omit(comparison_df)
#error in the model:
error <- comparison_df$predicted - comparison_df$actual
#RMSE:
rmse(error)   #2.055
#MAE:
mae(error)    #1.606


#######LOOCV:
# Define training control
train.control <- trainControl(method = "LOOCV")
# Train the model
ovrstfs_loocv_model <- train(overall ~., data = na.omit(train.data), method = "lm",
               trControl = train.control)
# Summarize the results
print(ovrstfs_loocv_model)
summary(ovrstfs_loocv_model)

#predicted overall:
ovrpred_loocv <- predict(ovrstfs_loocv_model, test.data)

comparison_df <- data.frame(cbind(actual= test.data$overall, predicted = ovrpred_loocv))
#View(comparison_df)

#correlation accuracy:
cor(comparison_df, use = "complete.obs")    #95.5%

#error using loocv method:
error <- comparison_df$predicted - comparison_df$actual
#RMSE:
rmse(error)    #2.05
#MSE:
mae(error)     #1.60


########k Fold Cross Validation:
set.seed(99) 
train.control <- trainControl(method = "cv", number = 10)
# Train the model
ovrfs_kfcv_model <- train(overall ~., data = na.omit(train.data), method = "lm",
               trControl = train.control)
# Summarize the results
print(ovrfs_kfcv_model)
summary(ovrfs_kfcv_model)

#predicted overall:
ovrpred_kfcv <- predict(ovrfs_kfcv_model, test.data)

comparison_df <- data.frame(cbind(actual= test.data$overall, predicted = ovrpred_kfcv))
#View(comparison_df)

#correlation accuracy:
cor(comparison_df, use = "complete.obs")    #95.5%

#error using loocv method:
error <- comparison_df$predicted - comparison_df$actual
#RMSE:
rmse(error)    #2.05
#MSE:
mae(error)     #1.06

```

#Interpretation:
```{r}

#Linear model using the forward stepwise selection dataset gave better results than
#the model using the full subset selection dataset since accuracy measures (cross validated) #RMSE and MAE for the former were smaller when compared to the latter.
```

#Lasso Regression for feature selection:
```{r}
library(glmnet)
data("swiss")

lasso_dataset <- f20_sans_gks %>% select(- short_name, -sofifa_id, -nationality, -club, -preferred_foot, 
     -team_position, -team_jersey_number, -work_rate)

#data types of columns:
#str(lasso_dataset)
#all integers

#remove overall from model matrix:
x_var <- model.matrix(overall~. , lasso_dataset)[,-4]
y_var <- lasso_dataset$overall
lambda_seq <- 10^seq(2, -2, by = -.1)

# Splitting the data into test and train
set.seed(86)
train = sample(1:nrow(x_var), nrow(x_var)/5)
x_test = (-train)
y_test = y_var[-train]

cv_output <- cv.glmnet(x_var[train,], y_var[train], 
            alpha = 1, lambda = lambda_seq)

# identifying best lamda
best_lam <- cv_output$lambda.min
best_lam
#best lambda value is 0.0158..
```

```{r}
#using minimum lambda value to build a lasso model again:
lasso_best <- glmnet(x_var[train,], y_var[train], alpha = 1, lambda = best_lam)
pred <- predict(lasso_best, s = best_lam, newx = x_var[-train,])

#comparing actual values and predicted values:
final <- data.frame(cbind(actual = y_var[-train], predicted = pred))

#coefficients of the best lasso model:
coef(lasso_best)
#coefs of variables with s0 as . have been shrunk to 0.

#error of the lasso model:
error = final$X1 - final$actual
#RMSE:
rmse(error)   #1.37
#MAE:
mae(error)    #1.07


#Of all the approaches, Lasso regression model gave the best accuracy measures on the 
#test set.
length(train)
```
